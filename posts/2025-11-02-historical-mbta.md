---
title: Parsing historical MBTA data
description: Buses and trains, now with time travel
tags: [transit, data]
---

# Transit and Data

Transit systems and public data are a great match. In my daily life, I interact with so many devices and applications which pull from transit data, from the [LED matrix in my living room](/projects/matrix2), to the app on my phone, and to the countdown clocks within the station itself. It's also incredibly accessible, too, as the myriad of DIY projects pulling in transit data demonstrates.

There are, in general, two types of data about a transit system: what the system is in _theory_ (schedules, routes, and stations determined months in advance), and what the system is in _practice_ (vehicle locations, arrival predictions, and dropped/added trips updated in realtime).

## Transit Systems in Theory

Describing what a transit system does in theory is the easy part. The [General Transit Feed Specification](https://gtfs.org/) defines a common format made up (in true 2006 fashion) of a set of TXT files contained within a ZIP file, each describing a different aspect of the system. For instance, `stops.txt` describes the vehicle stops and stations in the system, `stop_times.txt` describes when each stop is serviced by a vehicle trip, and `trips.txt` can specify the train number, whether bikes are aloud, and more.

The benefit of this approach is clear: sharing a common standard means that code written for one city can work seamlessly with others. Smaller transit operators can create these files by hand, and larger ones can build up the necessary automation to handle hundreds of routes and thousands of stops. Since these ZIP files usually only change when new schedules are determined, distributing them is straightforward and storing historical ones is easy to do.

## Transit Systems in Practice

Realtime data is where things get messy. The requirements are more demanding. Data usually needs to be generated and distributed without a human in the loop, and clients need to pull updates every minute or faster.

GTFS does offer a solution to this in the form of [GTFS-Realtime](https://gtfs.org/documentation/realtime/reference/). However, being a Google initiative, they chose to build this using [Protobuf](https://protobuf.dev/) as an interchange format, which requires specific language bindings to work with. My home system, the MBTA, chose to offer a [JSON version](https://github.com/mbta/gtfs-documentation/blob/master/reference/gtfs-realtime.md#json-feeds) of their feeds as well.

Even still, I tend to use their excellent, well-documented [service API](https://api-v3.mbta.com/docs/swagger/index.html) which makes it easier to ingest only the data relevant to the lines and stations I need. Interoperability with other systems is usually not a priority for my projects.

GTFS-Realtime, however, does not specify how _historical_ data should be represented and stored, leaving transit systems to invent bespoke formats for this data -- that is, if they choose to make it available at all.

# Historical Data at the MBTA

## LAMP

The MBTA has a service called [LAMP](https://performancedata.mbta.com/) (Lightweight Application for Measuring Performance), which does three things:

1. Publish historical GTFS schedule data, showing the state of the system "in theory" for any arbitrary date since 2009.
2. Publish historical subway performance data (the system "in practice") sorted by service date.
3. Publish miscellaneous datasets for MBTA-internal uses (while these are public, they are entirely undocumented).

That second point is what we'll focus on for parsing historical realtime data.

## Open Data Portal

The [MBTA Open Data Portal](https://mbta-massdot.opendata.arcgis.com/) contains lots of additional reports generated by the MBTA covering ridership, predictions accuracy, and more across the various transit modes. One such dataset is the [Bus Arrival Departure Times 2025](https://mbta-massdot.opendata.arcgis.com/datasets/924df13d845f4907bb6a6c3ed380d57a/about) dataset, which nicely complements the subway data published by the LAMP team.

# Let's get parsing

## Subway data

### Data format

The subway data we're interested in is distributed in the Parquet format, using URLs like this for each day of service:

```
https://performancedata.mbta.com/lamp/subway-on-time-performance-v1/YYYY-MM-DD-subway-on-time-performance-v1.parquet
```

The [Parquet file format](https://parquet.apache.org/) is an Apache project specification for storing tabular data efficiently. They pack the column data efficiently but don't require the receiver to know the schema definition like Protobuf does, which means we can easily throw these files into [Pandas](https://pandas.pydata.org/), the popular Python data analysis library.

```python
import pandas as pd

path = "https://performancedata.mbta.com/lamp/subway-on-time-performance-v1/2025-10-31-subway-on-time-performance-v1.parquet"
df = pd.read_parquet(path)

with open("data.json", "w") as out:
    out.write(df.to_json(orient="records"))
```

We can see that the data has 27 columns. While these aren't documented anywhere, here's how I assume the data is structured:

- Each entry describes a vehicle arriving and/or departing a station as part of a revenue trip.
- `stop_id` and `parent_station` describe which platform and station the vehicle was at: `stop_id` identifies the platform (for instance, `70513` means the northbound platform at _East Somerville_), and `parent_station` describes the station it belongs to (in this case, `place-esomr`).
- `move_timestamp` seems to be when the train starting moving _towards_ the given station, and `stop_timestamp` is when it reached the station.
- `travel_time_seconds` seems to be the amount of time it took the train to reach the given station, and `dwell_time_seconds` is how long it spent there.
- `service_date` describes the service date as an integer with a decimal expansion of the form YYYYMMDD... bruh
- `route_id` defines the specific route, such as `Blue`, `Green-E`, or `Red`. `branch_route_id` defines the branch, such as `Blue` (no branching), `Green-E`, or `Red-A`. I am unsure why the Red line branching is treated differently than the Green line here.
- `direction_id` is either `true` or `false`, depending on which way the train is heading. `direction` is the human-readable name, like `South`. `direction_destination` is the direction given as a destination station or station pair, like `Ashmont/Braintree` or `Boston College`.
- `start_time` seems to be the time that the vehicle started moving, given as "seconds since midnight at the start of the service day". Since the MBTA defines "service days" as starting and ending around 3 AM, the first vehicles have a `start_time` of around `17680` (4:54 AM) and the last ones have a `start_time` of around `95976` (2:39 AM). `stop_count` is the number of stops that vehicle has made since that time, I guess?
- `vehicle_id` is a unique identifier for the vehicle, `vehicle_label` is a human-readable label (usually the number of the first one or two cars), and `vehicle_consist` is the car numbers of each car in the train.
- `trip_id` identifies the trip that the vehicle was on.

### Simulating trips

Suppose I had been on the southbound platform at Sullivan Station at 5:15 PM. When would I have made it to North Station?

Let's start by finding all the trips which arrived at North Station coming southbound.

```python
trips_to_target = df[(df["parent_station"] == "place-north") & (df["direction"] == "South")]
```

| Stop ID | Parent Station | Move Timestamp | Stop Timestamp | Route ID | Direction | Trip ID |
| --- | --- | --- | --- | --- | --- | --- |
| 70026 | place-north | 1761902928.0 | 1761903013.0 | Orange | South | 70525780 |
| 70026 | place-north | 1761903114.0 | 1761903199.0 | Orange | South | 70525786 |
| 70026 | place-north | 1761903280.0 | 1761903367.0 | Orange | South | 70525792 |
| 70026 | place-north | 1761903673.0 | 1761903759.0 | Orange | South | 70525798 |

Now, let's find the earliest one of those trips which also stopped at Sullivan.

```python
trip_ids = trips_to_target["trip_id"].unique()

trips_from_start = df[
    (df["parent_station"] == "place-sull")
    & (df["direction"] == "South")
    & (df["trip_id"].isin(trip_ids))
]
```

| Stop ID | Parent Station | Move Timestamp | Stop Timestamp | Route ID | Direction | Trip ID |
| --- | --- | --- | --- | --- | --- | --- |
| 70030 | place-sull | 1761902684.0 | 1761902737.0 | Orange | South | 70525780 |
| 70030 | place-sull | 1761902876.0 | 1761902929.0 | Orange | South | 70525786 |
| 70030 | place-sull | 1761903061.0 | 1761903110.0 | Orange | South | 70525792 |
| 70030 | place-sull | 1761903454.0 | 1761903502.0 | Orange | South | 70525798 |

Right now, most of these are the same trip IDs, but now the timestamps match up with the train's stop at Sullivan. If we were dealing with different branches of the Green Line, for instance, this step would also filter out trips which don't run between our station pair.

Finally, let's find the first trip from the start which departed after we got to the station.

Times in this data are represented as Unix timestamps (i.e., seconds since 1970), seemingly in the local timezone (U.S. Eastern time). So, for instance, the first trip in our list arrived at the station at `1761902737` seconds, or at 5:25:37 AM on 2025-10-31.

```python
import datetime

timestamp = datetime.datetime.fromisoformat("2025-10-31 17:15:00").timestamp()
trips_after_time = trips_from_start[trips_from_start["stop_timestamp"] > timestamp]
```

| Stop ID | Parent Station | Move Timestamp | Stop Timestamp | Route ID | Direction | Trip ID |
| --- | --- | --- | --- | --- | --- | --- |
| 70030 | place-sull | 1761946007.0 | 1761946055.0 | Orange | South | 70526030 |
| 70030 | place-sull | 1761946114.0 | 1761946163.0 | Orange | South | 70526038 |
| 70030 | place-sull | 1761946438.0 | 1761946487.0 | Orange | South | 70526046 |
| 70030 | place-sull | 1761946646.0 | 1761946693.0 | Orange | South | 70526054 |

The first of those trips is trip ID `70526030`, which arrived at Sullivan at 5:27:35 PM.

```python
next_train = trips_after_time.loc[trips_after_time["stop_timestamp"].idxmin()]

train_arrival = df[
    (df["trip_id"] == next_train["trip_id"])
    & (df["parent_station"] == "place-north")
]
```

Looking up its arrival into North Station, we see:

| Stop ID | Parent Station | Move Timestamp | Stop Timestamp | Route ID | Direction | Trip ID |
| --- | --- | --- | --- | --- | --- | --- |
| 70026 | place-north | 1761946237.0 | 1761946322.0 | Orange | South | 70526030 |

It appears we would have arrived at 5:32:02 PM.

## Bus data

The bus data is a little different. The MBTA provides it as a ZIP file for each year, with a CSV file for each month. At time of writing, the latest one is `MBTA-Bus-Arrival-Departure-Times_2025-09.csv`.

The data is pretty straightforward, providing the following columns:

- `service_date` is self-explanatory.
- `route_id` is the bus number. Note that for some buses, the internal route ID does not match the consumer-facing bus number. For instance, route [89/93](https://www.mbta.com/schedules/8993/line) is identified as 194 internally, and the first [39](https://www.mbta.com/schedules/39/line) bus of the day is considered route 192 internally.
- `direction_id` is the direction identifier, which appears to only ever be `Outbound` or `Inbound`.
- `half_trip_id` is like the `trip_id` of the subway data, but since the outbound and inbound trip of a bus route often share a trip ID, this disambiguates them.
- `stop_id` is the identifier of the platform at which the bus stops. Large stations like Sullivan provide many bus platforms, each with its own ID.
- `point_type` specifies if this stop is a `Startpoint`, `Midpoint`, or `Endpoint` of the route.
- `scheduled` and `actual` give the scheduled and actual arrival times for the bus, respectively. However, for some reason, the date format is of the form `1900-01-01T14:28:00Z`... We'll dig into this more later.

Notably, not every stop is covered in this data, only the _time points_ (places along the route with a scheduled arrival time). However, the time points are typically placed at high-traffic stops like subway stations or the start and end of the line, so they are probably useful anyway.

### Basic parsing

Let's see if we can repeat a similar "simulated journey" to what we did with the subway, but with the bus data. Suppose I'm trying to get from Harvard to Hynes Convention Center station using the 1 bus on 2025-09-20 at 11:00 AM.

Ingesting the CSV file is quite easy:

```python
import pandas as pd

path = "MBTA_Bus_Arrival_Departure_Times_2025/MBTA-Bus-Arrival-Departure-Times_2025-09.csv"
df = pd.read_csv(path)
```

The first part is quite similar to simulating a subway trip. Let's try selecting all of the trips that arrived at our destination stop ID, stop [79](https://www.mbta.com/stops/79), then find the records for those trips departing from Harvard, stop [110](https://www.mbta.com/stops/110).

```python
trips_to_target = df[
    (df['stop_id'] == 79)
    & (df['direction_id'] == "Inbound")
]

trip_ids = trips_to_target["half_trip_id"].unique()

trips_from_start = df[
    (df["stop_id"] == 110)
    & (df["direction_id"] == "Inbound")
    & (df["half_trip_id"].isin(trip_ids))
]
```

| Service Date | Route ID | Direction ID | Half Trip ID | Stop ID | Scheduled | Actual |
| --- | --- | --- | --- | --- | --- | --- |
| 2025-09-01 | 01 | Inbound | 68099570 | 110 | 1900-01-01T11:31:00Z | 1900-01-01T11:44:24Z |
| 2025-09-01 | 01 | Inbound | 68099572 | 110 | 1900-01-01T12:40:00Z | 1900-01-01T13:01:02Z |
| 2025-09-01 | 01 | Inbound | 68099573 | 110 | 1900-01-01T22:06:00Z | 1900-01-01T22:54:09Z |
| 2025-09-01 | 01 | Inbound | 68099575 | 110 | 1900-01-01T23:42:00Z | 1900-01-02T00:18:43Z |

And finally, we need to filter by trips happening after our chosen start time, so we need to handle the problem of dates.

### Dates and times nonsense

How do we assemble the `service_date` and `scheduled`/`actual` fields into an actual timestamp like we got with the subway data?

Let's start by parsing the service date.

```python
timestamp = datetime.datetime.fromisoformat("2025-09-01")
>>> datetime.datetime(2025, 9, 1, 0, 0)
```

Now, let's parse the timestamp offset. Note that it is in UTC, not local time.

```python
offset = datetime.datetime.fromisoformat("1900-01-01T11:31:00Z")
>>> datetime.datetime(1900, 1, 1, 11, 31, tzinfo=datetime.timezone.utc)
```

Right now, the offset is an _aware_ datetime, meaning it contains timezone info. Combining aware datetimes with their counterparts, _naive_ datetimes, is usually not allowed. Let's make the service date an aware datetime as well.

You might be tempted to use the `astimezone` method, but this will convert the naive datetime to an aware datetime assuming the naive datetime is in local time, which is not what we want -- we want to keep the year/month/day values the same, but just attach timezone information to this instance. We can use the `replace` method and replace the `tzinfo` field.

```python
timestamp = timestamp.replace(tzinfo=datetime.UTC)
>>> datetime.datetime(2025, 9, 1, 0, 0, tzinfo=datetime.timezone.utc)
```

Cool. Now the only thing we need to do with the offset is subtract the placeholder date (1900-01-01). Python implements this nicely, where subtracting one datetime from another gives a _timedelta_ object.

```python
offset -= datetime.datetime(1900, 1, 1, tzinfo=datetime.UTC)
>>> datetime.timedelta(seconds=41460)
```

Now, we can add this to our service date:

```python
timestamp += offset
>>> datetime.datetime(2025, 9, 1, 11, 31, tzinfo=datetime.timezone.utc)
```

And finally, convert it from UTC to our local time, then strip the timezone info to match the behavior of our other code. If this were production code, we would want to only use aware datetimes... but we're just messing around so let's do what's easy.

```python
import zoneinfo
timestamp = timestamp.astimezone(zoneinfo.ZoneInfo("America/New_York"))
timestamp = timestamp.replace(tzinfo=None)
>>> datetime.datetime(2025, 9, 1, 7, 31)
```

Cool! So that trip was at 2025-09-01 at 7:31 AM.

### Pulling it together

Okay, back to the show. We were trying to filter by trips happening after a given time. Let's add a column to our dataframe with a proper timestamp to match our other data.

```python
import zoneinfo

def convert_timestamp(row):
    if not isinstance(row["actual"], str):
        return pd.NA

    timestamp = datetime.datetime.fromisoformat(row["service_date"])
    offset = datetime.datetime.fromisoformat(row["actual"])

    timestamp = timestamp.replace(tzinfo=datetime.UTC)
    offset -= datetime.datetime(1900, 1, 1, tzinfo=datetime.UTC)

    timestamp += offset
    timestamp = timestamp.astimezone(zoneinfo.ZoneInfo("America/New_York"))
    timestamp = timestamp.replace(tzinfo=None)
    return timestamp

df['timestamp'] = df.apply(convert_timestamp, axis=1)
```

After rebuilding `trips_from_start` with this new column, we can select the trips after our chosen time, choose the one that departed earliest, and see when it got to Hynes in a similar way to our subway trip simulator.

```python
timestamp = datetime.datetime.fromisoformat("2025-09-20 11:00:00")
trips_after_time = trips_from_start[trips_from_start['timestamp'] > timestamp]
next_bus = trips_after_time.loc[trips_after_time['timestamp'].idxmin()]
bus_arrival = df[(df['half_trip_id'] == next_bus['half_trip_id']) & (df['stop_id'] == 79)]
```

| Service Date | Route ID | Direction ID | Half Trip ID | Stop ID | Timestamp |
| --- | --- | --- | --- | --- | --- |
| 2025-09-20 | 01 | Inbound | 68311684 | 79 | 2025-09-20 11:24:05 |

I would've made it to Hynes at 11:24 AM. Not bad!

# Simulating longer journeys

Why do we care about simulating historical journeys, you might ask? It's useful for answering a few different types of questions:

- How early should I leave my house to make it to work on time 90% of the time?
- How reliably, on average, can I make certain connections between modes?

And, my favorite:

- If I wanted to visit every subway station in the MBTA as quickly as possible, what would be the fastest route?

## Simulating an existing speedrun

Transit system speedrunning is a phenomenon in which competitors attempt to travel through all stations within a system as quickly as possible.

My friend [Tris](https://tris.fyi) completed a speedrun about a year ago and documented her route in a [Mastodon thread](https://tacobelllabs.net/@tris/113724679621920495). Let's see if we can accurately simulate it!

I made a few improvements to the algorithm:

- Caching the processed data where possible!
- Instead of using `stop_timestamp` + `dwell_time_seconds`, I used the `move_timestamp` of the station immediately after the given one. This seemed much more accurate for terminus stations where `dwell_time_seconds` was set to null (despite those stations being where the train dwells for the longest amount of time).

For parts of the run involving walking, I set very optimistic transfer times because I can vouch for the fact that Tris walks very fast.

The code for this is [on GitHub](https://github.com/breqdev/mbta-simulate) if you want to play around with it.

| Station | Actual Time | Route | Direction | Simulated Time |
| --- | --- | --- | --- | --- |
| Riverside | [07:15](https://tacobelllabs.net/@tris/113724740717277822) | Green-D | East | 07:15 |
| Kenmore |  | Green-B | West | 07:48 |
| Boston College | [08:18](https://tacobelllabs.net/@tris/113724981377517592) | WALK | WALK | 08:15 |
| Cleveland Circle | [08:41](https://tacobelllabs.net/@tris/113725072297288138) | Green-C | East | 08:25 |
| Park St | [09:12](https://tacobelllabs.net/@tris/113725192574260269) | Green-E | West | 09:07 |
| Heath St | [09:45](https://tacobelllabs.net/@tris/113725324958185355) | 39 | Outbound | 09:42 |
| Forest Hills | [09:58](https://tacobelllabs.net/@tris/113725376738178438) | Orange | North | 09:54 |
| Downtown Crossing | [10:21](https://tacobelllabs.net/@tris/113725464921047879) | Red | North | 10:17 |
| Alewife | [10:50](https://tacobelllabs.net/@tris/113725578546237980) | Red | South | 10:43 |
| Davis | [10:54](https://tacobelllabs.net/@tris/113725596752822002) | 96 | Outbound | 10:46 |
| Medford/Tufts | [11:04](https://tacobelllabs.net/@tris/113725633977529438) | Green-E | West | 11:07 |
| East Somerville |  | WALK | WALK | 11:16 |
| Union Sq | [11:24](https://tacobelllabs.net/@tris/113725713807971548) | Green-D | West | 11:21 |
| North Sta | 11:36 | Orange | North | 11:36 |
| Oak Grove | [12:05](https://tacobelllabs.net/@tris/113725875079532776) | Orange | South | 12:03 |
| Haymarket |  | WALK | WALK | 12:23 |
| Bowdoin | [12:35](https://tacobelllabs.net/@tris/113725990981012681) | Blue | North | 12:28 |
| Wonderland | [12:57](https://tacobelllabs.net/@tris/113726079382870810) | Blue | South | 12:50 |
| State |  | WALK | WALK | 13:08 |
| Downtown Crossing | [13:17](https://tacobelllabs.net/@tris/113726156172913175) | Red-A | South | 13:13 |
| Ashmont | [13:41](https://tacobelllabs.net/@tris/113726251169030970) | Mattapan | Outbound | 13:38 |
| Mattapan | [13:57](https://tacobelllabs.net/@tris/113726315814984961) | Mattapan | Inbound | 13:51 |
| Ashmont | [14:08](https://tacobelllabs.net/@tris/113726356806389810) | Red-A | North | 14:05 |
| JFK/UMass | [14:23](https://tacobelllabs.net/@tris/113726417955542565) | Red-B | South | 14:20 |
| Braintree | [14:47](https://tacobelllabs.net/@tris/113726512385880967) |  |  | 14:45 |

Not too bad! Especially considering that the "actual time" column is based on Mastodon post timestamps so probably 1-2 minutes behind the actual timing.

## Generating the optimal route

My eventual plan with this is to use it to learn more about what makes an ideal MBTA speedrun, including the route, timing, etc. It's been a bucket list item of mine for a while to do a speedrun, and I want to see if I can find something new in terms of route, timing, etc. I think it's unlikely I'll find anything that substantial that could make a difference, but maybe it's possible...

Since running this type of simulation becomes extremely fast, there are a lot of places you could take this other than just tracing manually entered routes:

- Taking a graph representation of the MBTA system, running a search algorithm to identify a large set of possible routes, and running simulations on each to estimate real-world timing
- Simulating a route at various times of day, days of the week, or even months of the year to find the best time to start a run
- Implementing logic to simulate making decisions at each step of the route based on upcoming train times (e.g., whether an Ashmont or Braintree train arrives first), to evaluate when to make those decisions

# Takeaways

I hadn't really done an in-depth data analysis project quite like this before. I definitely learned a ton!

Ingesting data into a data structure like this is something I usually consider "grunt work," but working on this showed me how wrong that assumption can be. I tried to throw a lot of this work to an LLM, only to watch it struggle against the date and timezone issues and completely miss the nuance between `stop_timestamp` and `move_timestamp`. While I got much further than it did (thankfully for the sake of my job security), it still required me to step away from the problem for a day before I could nail the accuracy.

I had also heard people constantly talk about how timezones are hard and date parsing is a mess, but had been spared the brunt of that struggle until now. I have discovered that there are a lot of bad ways to represent dates and times in software. I feel lucky that I do not need to deal with things like this more often.

The last thing I'll mention is that this project highlighted the difference between working with data in a domain where a dominant format exists (i.e., realtime GTFS), and working in a domain where implementors have no common format to use (i.e., historical transit data). I find it easy to get annoyed at format specifications not perfectly matching what I want to do... but when standardized formats work, they're pretty great!
